{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb68bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "import os\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109a33f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all PDFs in the data folder\n",
    "data_folder = '../data'\n",
    "documents = []\n",
    "for file_name in os.listdir(data_folder):\n",
    "    if file_name.endswith('.pdf'):\n",
    "        loader = PyPDFLoader(os.path.join(data_folder, file_name))\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77500f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into manageable chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b5c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings and vector store\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e59757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system prompt\n",
    "system_prompt = \"\"\"\n",
    "You are an intelligent and helpful assistant designed to answer questions based on CTSE (Current Trends in Software Engineering) lecture notes. \n",
    "Your primary goal is to provide accurate, concise, and contextually relevant answers to the user's questions. \n",
    "The lecture notes cover topics such as software engineering principles, AI/ML trends, software development methodologies, and related concepts. \n",
    "If a question is outside the scope of the lecture notes, politely inform the user that the information is not available. \n",
    "Always maintain a professional tone and avoid making up information. \n",
    "When answering, ensure your responses are clear and easy to understand, and provide examples or explanations when necessary. \n",
    "If the user asks for clarification, respond patiently and provide additional details. \n",
    "Your responses should be tailored to help students understand the material effectively.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9969463",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = \"\"\"Context: \n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ae63e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template that includes both context and query variables\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d0fd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the LLM and Retrieval-based QA chain\n",
    "llm = ChatOpenAI(model=\"gpt-4\", openai_api_key=openai_api_key)\n",
    "\n",
    "# Create a document chain that combines the retrieved documents\n",
    "document_chain = create_stuff_documents_chain(llm, chat_prompt)\n",
    "\n",
    "# Create a retrieval chain that uses the retriever and the document chain\n",
    "qa_chain = create_retrieval_chain(vectorstore.as_retriever(), document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d9c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot interaction\n",
    "while True:\n",
    "    query = input(\"Ask a question about CTSE lecture notes: \")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    try:\n",
    "        response = qa_chain.invoke({\"input\": query})\n",
    "        print(f\"Answer: {response['answer']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ctse-chatbot)",
   "language": "python",
   "name": "ctse-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
